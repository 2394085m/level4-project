
## *Facial expressions in Mozilla Hubs* 
#### *Stuart McLaughlin* 
#### *2394085* 

## Proposal
### Motivation
*Implementing facial expressions using facial recognition AI for Mozilla Hubs (an open-source vr platform)*



### Aims
*Have a working real-time facial recognition AI detect the facial expression of the user through their webcam and have that facial expression be displayed on the in-game avatar's face.*




## Progress
* Working blender model for displaying different facial expressions
* Identification of a javascript AI model to use for detecting expressions
* Understanding how to update the shape keys for the blender model with audio feedback


## Problems and risks
### Problems
* Setting up Mozilla Hubs client so that a modified version could be run on the local machine.
* Getting shape keys to properly respond to audio feedback with the hubs blender extension.
* Developing custom feedback options for the model to allow changing of expressions from the webcam.


### Risks
* Risk of not getting the features implemented in time for the user study. This will be mitigated by implementing a testable version over the December holiday.
* Risk of scheduling with user study and then having to write the dissertation. This will be mitigated by planning the user study far in advance and getting the analysis ready for when the data comes back.


## Plan
*[Time plan, in roughly weekly to monthly blocks, up until submission week]*


