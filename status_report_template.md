
## *Facial expressions in Mozilla Hubs* 
#### *Stuart McLaughlin* 
#### *2394085* 

## Proposal
### Motivation
*Implementing facial expressions using facial recognition AI for Mozilla Hubs (an open-source vr platform)*



### Aims
*Have a working real-time facial recognition AI detect the facial expression of the user through their webcam and have that facial expression be displayed on the in-game avatar's face.*




## Progress
* Working blender model for displaying different facial expressions
* Identification of a javascript AI model to use for detecting expressions
* Understanding how to update the shape keys for the blender model with audio feedback


## Problems and risks
### Problems
* Setting up Mozilla Hubs client so that a modified version could be run on the local machine.
* Getting shape keys to properly respond to audio feedback with the hubs blender extension.
* Developing custom feedback options for the model to allow changing of expressions from the webcam.


### Risks
* Risk of not getting the features implemented in time for the user study. This will be mitigated by implementing a testable version over the December holiday.
* Risk of scheduling with user study and then having to write the dissertation. This will be mitigated by planning the user study far in advance and getting the analysis ready for when the data comes back.


## Plan
* DEC - Over the December holiday will work on creating the minimum valued product before the semester starts to put the project back on track.
* JAN - The project will be refined and any remaining development of it will be finalised here (e.g. bug fixes)
* FEB - User analysis/User study will be conducted early on in the month and then analysis of the data will be carried out in the 2nd half of the month.
* MAR - The entire month will be dedicated to dissertation write up


